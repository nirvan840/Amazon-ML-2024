{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for absence of units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to display an image from a URL\n",
    "def display_image_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    # Display the image\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')  # Hide axes for a cleaner display\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Missing Units: 100%|██████████| 131187/131187 [00:00<00:00, 293387.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unitless: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"cleaned_test_FINAL_500AM.csv\")\n",
    "df3 = pd.read_csv(\"1-56.csv\")\n",
    "\n",
    "# Counters\n",
    "count = 0\n",
    "unitless = 0\n",
    "unitless_list = []\n",
    "\n",
    "df_inuse = df1\n",
    "for index, (row1, row2) in tqdm(enumerate(zip(df3.itertuples(), df_inuse.itertuples())), total=len(df3), desc = \"Calculating Missing Units\"):\n",
    "    # Getting additional info\n",
    "    entity_name = getattr(row1, 'entity_name')\n",
    "    current_url = getattr(row1, 'image_link')\n",
    "    # Getting prediction info\n",
    "    amazon_index = getattr(row2, 'index')\n",
    "    prediction = getattr(row2, 'prediction')\n",
    "    #prediction = getattr(row2, 'entity_value')\n",
    "    str_pred = str(prediction)\n",
    "\n",
    "    # Checking if number present in unit i.e. alphabet must be present\n",
    "    if any(char.isdigit() for char in str_pred):\n",
    "        if not any(char.isalpha() for char in str_pred):\n",
    "            #print(f\"{amazon_index} | {prediction}\")\n",
    "            unitless_list.append((amazon_index, current_url, entity_name, str_pred))\n",
    "            unitless += 1\n",
    "\n",
    "# Unitless\n",
    "print(f\"Unitless: {unitless}\")\n",
    "\n",
    "for pair in unitless_list:\n",
    "    print(f\"{pair[0]} | {pair[1]} | {pair[2]} | {pair[3]}\")\n",
    "    display_image_from_url(pair[1])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messed up Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index       prediction\n",
      "0      0  6.68 centimetre\n",
      "1      1  42.0 centimetre\n",
      "2      2              NaN\n",
      "3      3              NaN\n",
      "4      4              NaN\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Load the CSV file\n",
    "dirty_rec = pd.read_csv('No_Depth_ItemWeight.csv')\n",
    "\n",
    "# Define the entity-unit mappings\n",
    "entity_unit_map = {\n",
    "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'item_weight': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
    "    'maximum_weight_recommendation': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
    "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
    "    'wattage': {'kilowatt', 'watt'},\n",
    "    'item_volume': {'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce', 'gallon', 'imperial gallon', 'litre', 'microlitre', 'millilitre', 'pint', 'quart'}\n",
    "}\n",
    "\n",
    "# Flatten the allowed units into a set\n",
    "allowed_units = {unit for entity in entity_unit_map for unit in entity_unit_map[entity]}\n",
    "\n",
    "# Handle common mistakes in units\n",
    "def common_mistake(unit):\n",
    "    if unit in allowed_units:\n",
    "        return unit\n",
    "    if unit.replace('ter', 'tre') in allowed_units:\n",
    "        return unit.replace('ter', 'tre')\n",
    "    if unit.replace('feet', 'foot') in allowed_units:\n",
    "        return unit.replace('feet', 'foot')\n",
    "    return unit\n",
    "\n",
    "# Parse a string to extract the numeric value and the unit, and flag dirty entries\n",
    "def parse_string(s):\n",
    "    s_stripped = \"\" if s is None or str(s) == 'nan' else s.strip()\n",
    "    if s_stripped == \"\":\n",
    "        return None, None, False\n",
    "    # Regex to check if the string follows \"number + space + unit\"\n",
    "    pattern = re.compile(r'^-?\\d+(\\.\\d+)?\\s+[a-zA-Z\\s]+$')\n",
    "    if not pattern.match(s_stripped):\n",
    "        return None, None, True  # Dirty entry due to wrong format\n",
    "    \n",
    "    # Split into number and unit parts\n",
    "    parts = s_stripped.split(maxsplit=1)\n",
    "    number = float(parts[0])\n",
    "    unit = common_mistake(parts[1])\n",
    "    \n",
    "    if unit not in allowed_units:\n",
    "        return number, unit, True  # Dirty entry due to invalid unit\n",
    "    \n",
    "    return number, unit, False  # Clean entry\n",
    "\n",
    "# Apply the parsing function to the 'prediction' column\n",
    "# Only keep the dirty flag (no need to add other columns)\n",
    "dirty_rec['is_dirty'] = dirty_rec['prediction'].apply(lambda x: parse_string(x)[2])\n",
    "\n",
    "# Set the 'prediction' values of dirty entries to blank\n",
    "dirty_rec.loc[dirty_rec['is_dirty'] == True, 'prediction'] = ''\n",
    "\n",
    "# Drop the 'is_dirty' column after processing\n",
    "dirty_rec.drop(columns=['is_dirty'], inplace=True)\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "dirty_rec.to_csv('Cleaned_No_Depth_ItemWeight.csv', index=False)\n",
    "\n",
    "# View the modified DataFrame\n",
    "print(dirty_rec.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking number of entires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating entries: 100%|██████████| 131187/131187 [00:04<00:00, 29522.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: 56530/131187\n",
      "% Filled: 30.1144808408402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"No_Width.csv\")\n",
    "count = 0\n",
    "\n",
    "df_inuse = df1\n",
    "for index, row in tqdm(df_inuse.iterrows(), total=len(df_inuse), desc=\"Calculating entries\"):\n",
    "    prediction = row['prediction']\n",
    "    if any(char.isdigit() for char in str(prediction)): count += 1\n",
    "\n",
    "print(f\"Predictions: {count}/{len(df1)}\")\n",
    "print(f\"% Filled: {count/(len(df1)+count)*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No_Depth\n",
    "    Predictions: 83355/131187\n",
    "    % Filled: 38.85253237128394\n",
    "\n",
    "cleaned_No_Depth_Working \n",
    "    Predictions: 83409/131187\n",
    "    % Filled: 38.867919252921766\n",
    "    \n",
    "test_final_wattage_update\n",
    "    Predictions: 102396/131187\n",
    "    % Filled: 43.837094309089274"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing all of a Quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing width: 100%|██████████| 131187/131187 [00:00<00:00, 399027.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "c = True\n",
    "count = 0\n",
    "quantity = \"width\"\n",
    "\n",
    "csv_nirvan = 'Priyansh/priyansh_1.csv'\n",
    "df_nirvan = pd.read_csv(csv_nirvan)\n",
    "\n",
    "# A\n",
    "#if not c: df = pd.read_csv(\"test_final_wattage_update.csv\")\n",
    "#if c: df = pd.read_csv(\"No_Depth.csv\")\n",
    "\n",
    "# B\n",
    "if not c: df = pd.read_csv(\"No_Depth.csv\")\n",
    "if c: df = pd.read_csv(\"No_Width.csv\")\n",
    "\n",
    "result_df = pd.DataFrame(columns=['index', 'prediction'])\n",
    "\n",
    "for index, (row1, row2) in tqdm(enumerate(zip(df.itertuples(), df_nirvan.itertuples())), total=len(df), desc=f\"Removing {quantity}\"):\n",
    "\n",
    "    # Orignial entity_name\n",
    "    index_amazon = getattr(row2, 'index')\n",
    "    entity_name = getattr(row2, 'entity_name')\n",
    "    prediction = getattr(row1, 'prediction')\n",
    "\n",
    "    # Removing depth\n",
    "    if entity_name == quantity and any(char.isdigit() for char in str(prediction)):\n",
    "        if not c: result_df = result_df.append({'index': index_amazon, 'prediction': \"\"}, ignore_index=True)\n",
    "        #print(index_amazon)\n",
    "        count += 1\n",
    "    elif any(char.isdigit() for char in str(prediction)):\n",
    "        if not c: result_df = result_df.append({'index': index_amazon, 'prediction': str(prediction)}, ignore_index=True)\n",
    "    else:\n",
    "        if not c: result_df = result_df.append({'index': index_amazon, 'prediction': \"\"}, ignore_index=True)\n",
    "    \n",
    "    #if index == 20: break\n",
    "\n",
    "# Writing to File\n",
    "if not c: \n",
    "    result_df.to_csv('No_Width.csv', index=False)\n",
    "    print(\".csv file written\")\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
